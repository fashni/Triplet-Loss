{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/fashni/Triplet-Loss.git\n",
    "%cd Triplet-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFW-df\n",
    "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
    "!wget https://media.fashni.space/pub/dataset/lfw-deepfunneled/train.json\n",
    "!wget https://media.fashni.space/pub/dataset/lfw-deepfunneled/valid.json\n",
    "!tar -xzf lfw-deepfunneled.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset import BatchGenerator, TripletGenerator\n",
    "from models import facenet, inception, inception_resnet, siamnet\n",
    "from utils import compute_metrics, compute_preds, get_images_and_labels\n",
    "\n",
    "models = {\n",
    "    \"facenet\": facenet,\n",
    "    \"inception\": inception,\n",
    "    \"inception_resnet\": inception_resnet,\n",
    "    \"siamnet\": siamnet\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 69\n",
    "\n",
    "# Dataset Parameters\n",
    "train_path = 'train.json'\n",
    "valid_path = 'valid.json'\n",
    "batch_size = 32\n",
    "augment = False\n",
    "dset_name = \"lfw\"\n",
    "\n",
    "# Model Parameters\n",
    "input_shape = (160, 160, 3)\n",
    "embedding_size = 128\n",
    "model_name = \"facenet\"\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "\n",
    "# Loss Parameters\n",
    "strategy = \"batch_all\" # siamese, batch_all, or batch_hard\n",
    "margin = 0.5\n",
    "squared = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator\n",
    "if strategy == \"siamese\":\n",
    "  train_triplet_generator = TripletGenerator(train_path, batch_size=batch_size, input_shape=input_shape, augment=augment, seed=seed)\n",
    "  valid_triplet_generator = TripletGenerator(valid_path, batch_size=batch_size, input_shape=input_shape, augment=False, seed=seed)\n",
    "else:\n",
    "  train_dataset_generator = BatchGenerator(train_path, batch_size=batch_size, input_shape=input_shape, augment=augment, seed=seed)\n",
    "  valid_dataset_generator = BatchGenerator(valid_path, batch_size=batch_size, input_shape=input_shape, augment=False, seed=seed)\n",
    "\n",
    "# Get the total images in the dataset\n",
    "n_train = train_triplet_generator.n_images\n",
    "n_valid = valid_triplet_generator.n_images\n",
    "\n",
    "# Get datasets\n",
    "train_dataset = train_triplet_generator.get_dataset()\n",
    "valid_dataset = valid_triplet_generator.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models[model_name](input_shape, embedding_size, strategy=strategy, margin=margin, squared=squared)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, weighted_metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation steps per epoch\n",
    "train_steps = min(200, -(-n_train // batch_size))\n",
    "valid_steps = min(50, -(-n_valid // batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "hist = model.fit(\n",
    "  train_dataset.take(train_steps),\n",
    "  epochs=epochs,\n",
    "  validation_data=valid_dataset.take(valid_steps),\n",
    "  verbose=1,\n",
    "  initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BatchGenerator(valid_path, input_shape=input_shape, augment=False, seed=seed).get_dataset()\n",
    "images, labels = get_images_and_labels(test_dataset, 100)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, embeddings = compute_preds(model, images, labels, batch_size, squared=squared, verbose=1)\n",
    "fpr, tpr, prc, acc, f1, thres, auc = compute_metrics(y_true, y_pred)\n",
    "j = (tpr-fpr).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{auc = }\")\n",
    "print(f\"{f1[j] = }\")\n",
    "print(f\"{acc[j] = }\")\n",
    "print(f\"{prc[j] = }\")\n",
    "print(f\"{tpr[j] = }\")\n",
    "print(f\"{fpr[j] = }\")\n",
    "print(f\"{thres[j] = }\")\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{model_name}_{dset_name}.weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
